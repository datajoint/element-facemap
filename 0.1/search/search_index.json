{"config": {"lang": ["en"], "separator": "[\\s\\-]+", "pipeline": ["stopWordFilter"]}, "docs": [{"location": "", "title": "Element Facemap", "text": "<p>DataJoint Element for tracking facial movements of a mouse with the Facemap analysis package. DataJoint Elements collectively standardize and automate data collection and analysis for neuroscience experiments. Each Element is a modular pipeline for data storage and processing with corresponding database tables that can be combined with other Elements to assemble a fully functional pipeline.</p> <p></p> <p>Visit the Concepts page for more information on estimating facial movements and Element Facemap. To get started with building your data pipeline visit the Tutorials page.</p>"}, {"location": "CHANGELOG/", "title": "Changelog", "text": "<p>Observes Semantic Versioning standard and Keep a Changelog convention.</p>"}, {"location": "CHANGELOG/#015-2023-05-11", "title": "0.1.5 - 2023-05-11", "text": "<ul> <li>Fix - <code>.ipynb</code> dark mode output for all notebooks.</li> <li>Fix - Remove <code>GOOGLE_ANALYTICS_KEY</code> from <code>u24_element_release_call.yml</code>.</li> <li>Remove - <code>.staging workflows</code> from CI/CD</li> </ul>"}, {"location": "CHANGELOG/#014-2023-04-28", "title": "0.1.4 - 2023-04-28", "text": "<ul> <li>Fix - <code>.ipynb</code> output in tutorials is not visible in dark mode.</li> </ul>"}, {"location": "CHANGELOG/#013-2022-10-11", "title": "0.1.3 - 2022-10-11", "text": "<ul> <li>Add - CICD workflows for PyPI release</li> <li>Fix - lagging motion index</li> </ul>"}, {"location": "CHANGELOG/#012-2022-05-17", "title": "0.1.2 - 2022-05-17", "text": "<ul> <li>Fix - Recording duration attribute name</li> </ul>"}, {"location": "CHANGELOG/#011-2022-05-13", "title": "0.1.1 - 2022-05-13", "text": "<ul> <li>Fix - any -&gt; np.any</li> </ul>"}, {"location": "CHANGELOG/#010-2022-05-10", "title": "0.1.0 - 2022-05-10", "text": "<ul> <li>Add - Adopt black formatting into code base</li> </ul>"}, {"location": "CHANGELOG/#001-2022-03-29", "title": "0.0.1 - 2022-03-29", "text": "<ul> <li>Add - Multiple file processing</li> <li>Add - Support for avi video files</li> <li>Add - Stores left singular vector, right singular vector, and the non-zero elements of   the diagonal matrix</li> <li>Add - Output directory inferral, if unspecified.</li> </ul>"}, {"location": "citation/", "title": "Citation", "text": "<p>If your work uses this Element, please cite the following manuscript and Research Resource Identifier (RRID).</p> <ul> <li>Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D,   Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for   Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358</li> </ul> <ul> <li>DataJoint Elements (RRID:SCR_021894) -   Element Facemap (version 0.1.5)</li> </ul>"}, {"location": "concepts/", "title": "Concepts", "text": ""}, {"location": "concepts/#facial-motion-tracking", "title": "Facial Motion Tracking", "text": "<p>Neuroscience often involves studying relationships between neural activity and subject behavior. Many mammals, including mice1, exhibit facial expressions that convey information about emotional and neuronal states. Facemap2 is software designed to automate the process of quantifying facial movements, including whisker, eye, and pupil movements, using computer vision.</p> <p>Facemap allows users to designate regions of interest (ROIs) as either rectangles or ellipses drawn on top of example frames. The software then runs singular value decomposition on these regions on both the raw movie frames and frame-wise difference values, which indicate motion. The result of this principle component analysis is a set of components, each representing distinct facial features. For best results, researchers should use fixed camera recordings, ensuring that all motion within the ROIs reflects the subject's facial movement.</p>"}, {"location": "concepts/#key-partnerships", "title": "Key Partnerships", "text": "<p>Element Facemap was developed in collaboration with Hui Chen Lu's Lab at Indiana University Bloomington.  Our team also works with the Facemap developers to promote integration and interoperability between Facemap and the DataJoint Element Facemap (see Sustainability Roadmap).</p>"}, {"location": "concepts/#element-features", "title": "Element Features", "text": "<p>Through our interviews and direct collaborations, we identified the common motifs to create Element Facemap.</p> <p>Major features include:</p> <ul> <li>Ingestion and storage of input video metadata.</li> <li>Queueing and triggering of Facemap analysis.</li> <li>Ingestion of analysis outcomes as motion and video principle components.</li> </ul>"}, {"location": "concepts/#element-architecture", "title": "Element Architecture", "text": "<p>Each node in the following diagram represents the analysis code in the workflow and the corresponding tables in the database.  Within the workflow, Element Facemap connects to upstream Elements including Lab, Animal, and Session. For more detailed documentation on each table, see the API docs for the respective schemas.</p> <p></p>"}, {"location": "concepts/#subject-schema-api-docs", "title": "<code>subject</code> schema (API docs)", "text": "<p>Although not required, most choose to connect the <code>Session</code> table to a <code>Subject</code>   table.</p> Table Description Subject Basic information of the research subject."}, {"location": "concepts/#session-schema-api-docs", "title": "<code>session</code> schema (API docs)", "text": "Table Description Session Unique experimental session identifier."}, {"location": "concepts/#facial_behavior_estimation-schema-api-docs", "title": "<code>facial_behavior_estimation</code> schema (API docs)", "text": "Table Description VideoRecording Video(s) from one recording session, for Facial Motion Tracking. RecordingInfo Information extracted from video file. FacemapTask Staging table for pairing of recording and Facemap parameters before processing. FacemapProcessing Automated table to execute Facemap with inputs from FacemapTask. FacialSignal Results of the Facemap analysis. FacialSignal.Region Region properties. FacialSignal.MotionSVD Components of the SVD from motion video. FacialSignal.MovieSVD Components of the SVD from movie video. FacialSignal.Summary Average frames for movie and motion videos. <ol> <li> <p>Dolensek, N., Gehrlach, D. A., Klein, A. S., &amp; Gogolla, N. (2020). Facial expressions of emotion states and their neuronal correlates in mice. Science, 368(6486), 89-94.\u00a0\u21a9</p> </li> <li> <p>Syeda, A., Zhong, L., Tung, R., Long, W., Pachitariu, M., &amp; Stringer, C. (2022). Facemap: a framework for modeling neural activity based on orofacial tracking. bioRxiv, 2022-11\u00a0\u21a9</p> </li> </ol>"}, {"location": "tutorials/", "title": "Tutorials", "text": ""}, {"location": "tutorials/#installation", "title": "Installation", "text": "<p>Installation of the Element requires an integrated development environment and database. Instructions to setup each of the components can be found on the User Instructions page. </p> <p>There, you'll find instructions referencing other DataJoint Element 'Workflows' (e.g., workflow for Element DeepLabCut), which serves as a model for developing custom pipelines. While the workflow for Facemap is still under development, these can serve as a model for integrating Elements into a pipeline.</p>"}, {"location": "api/element_facemap/facial_behavior_estimation/", "title": "facial_behavior_estimation.py", "text": ""}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.activate", "title": "<code>activate(facemap_schema_name, *, create_schema=True, create_tables=True, linking_module=None)</code>", "text": "<p>Activate schema.</p> <p>Parameters:</p> Name Type Description Default <code>facemap_schema_name</code> <code>str</code> <p>Schema name on the database server to activate the <code>facemap</code> element</p> required <code>create_schema</code> <code>bool</code> <p>When True (default), create schema in the database if it does not yet exist.</p> <code>True</code> <code>create_tables</code> <code>bool</code> <p>When True (default), create tables in the database if they do not yet exist.</p> <code>True</code> <code>linking_module</code> <code>str</code> <p>A module name or a module containing the required dependencies to activate the <code>facial_behavior_estimation</code> module:</p> <code>None</code> <p>Dependencies:</p> Upstream tables <ul> <li>Session: A parent table to VideoRecording, identifying a recording session</li> <li>Equipment: A parent table to VideoRecording, identifying video recording equipment</li> </ul> Functions <ul> <li>get_facemap_root_data_dir() -&gt; list     Retrieves the root data directory(s) with face recordings for all     subject/sessions. Returns a string for the full path to the root data directory.</li> <li>get_facemap_processed_data_dir(session_key: dict) -&gt; str     Optional function to retrieve the desired output directory     for Facemap files for a given session. If unspecified,     the output is stored in the video folder for the session, which is the default behavior of Facemap.     Returns a string of the absolute path of the output directory.</li> </ul> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def activate(\n    facemap_schema_name, *, create_schema=True, create_tables=True, linking_module=None\n):\n\"\"\"Activate schema.\n\n    Args:\n        facemap_schema_name (str): Schema name on the database server to activate the\n            `facemap` element\n        create_schema (bool): When True (default), create schema in the database if it\n            does not yet exist.\n        create_tables (bool): When True (default), create tables in the database if\n            they do not yet exist.\n        linking_module (str): A module name or a module containing the required\n            dependencies to activate the `facial_behavior_estimation` module:\n\n    Dependencies:\n    Upstream tables:\n        + Session: A parent table to VideoRecording, identifying a recording session\n        + Equipment: A parent table to VideoRecording, identifying video recording equipment\n    Functions:\n        + get_facemap_root_data_dir() -&gt; list\n            Retrieves the root data directory(s) with face recordings for all\n            subject/sessions. Returns a string for the full path to the root data directory.\n        + get_facemap_processed_data_dir(session_key: dict) -&gt; str\n            Optional function to retrieve the desired output directory\n            for Facemap files for a given session. If unspecified,\n            the output is stored in the video folder for the session, which is the default behavior of Facemap.\n            Returns a string of the absolute path of the output directory.\n    \"\"\"\n    if isinstance(linking_module, str):\n        linking_module = importlib.import_module(linking_module)\n    assert inspect.ismodule(\n        linking_module\n    ), \"The argument 'dependency' must be a module's name or a module\"\n    assert hasattr(\n        linking_module, \"get_facemap_root_data_dir\"\n    ), \"The linking module must specify a lookup function for a root data directory\"\n\n    global _linking_module\n    _linking_module = linking_module\n\n    # activate\n    schema.activate(\n        facemap_schema_name,\n        create_schema=create_schema,\n        create_tables=create_tables,\n        add_objects=_linking_module.__dict__,\n    )\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.get_facemap_root_data_dir", "title": "<code>get_facemap_root_data_dir()</code>", "text": "<p>Pull the relevant function from the parent namespace to specify the root data directory(s).</p> <p>It is recommended that all paths in DataJoint Elements are stored as relative paths, with respect to some user-configured \"root\" directory. The root(s) may vary between data modalities and user machines.</p> <p>Returns:</p> Name Type Description <code>paths</code> <code>list</code> <p>list of path(s) to root data directory(s) for Facemap</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def get_facemap_root_data_dir():\n\"\"\"Pull the relevant function from the parent namespace to specify the root data directory(s).\n\n    It is recommended that all paths in DataJoint Elements are stored as relative\n    paths, with respect to some user-configured \"root\" directory. The\n    root(s) may vary between data modalities and user machines.\n\n    Returns:\n        paths (list): list of path(s) to root data directory(s) for Facemap\n    \"\"\"\n    root_directories = _linking_module.get_facemap_root_data_dir()\n    if isinstance(root_directories, (str, Path)):\n        root_directories = [root_directories]\n\n    if hasattr(_linking_module, \"get_facemap_processed_data_dir\"):\n        root_directories.append(_linking_module.get_facemap_processed_data_dir())\n\n    return root_directories\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.get_facemap_processed_data_dir", "title": "<code>get_facemap_processed_data_dir()</code>", "text": "<p>Facemap output directory</p> <p>If specified by the user, this function provides Facemap with an output directory for processed files. If unspecified, the output is stored in the video directory for the session, which is the default behavior of Facemap.</p> <p>Returns:</p> Name Type Description <code>path</code> <code>str</code> <p>path to Facemap output directory</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def get_facemap_processed_data_dir() -&gt; str:\n\"\"\"Facemap output directory\n\n    If specified by the user, this function provides Facemap with an output\n    directory for processed files. If unspecified, the output is stored in the video directory for the session, which is the default behavior of Facemap.\n\n    Returns:\n        path (str): path to Facemap output directory\n    \"\"\"\n    if hasattr(_linking_module, \"get_facemap_processed_data_dir\"):\n        return _linking_module.get_facemap_processed_data_dir()\n    else:\n        return get_facemap_root_data_dir()[0]\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.get_facemap_video_files", "title": "<code>get_facemap_video_files(video_key)</code>", "text": "<p>Retrieve the list of video recording files.</p> <p>Parameters:</p> Name Type Description Default <code>video_key</code> <code>dict</code> <p>Primary key of an entry in the VideoRecording table.</p> required <p>Returns:</p> Type Description <code>List[Path]</code> <p>List of absolute POSIX paths of the video files.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def get_facemap_video_files(video_key: dict) -&gt; List[Path]:\n\"\"\"Retrieve the list of video recording files.\n\n    Args:\n        video_key: Primary key of an entry in the VideoRecording table.\n\n    Returns:\n        List of absolute POSIX paths of the video files.\n    \"\"\"\n    return _linking_module.get_facemap_video_files(video_key)\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.VideoRecording", "title": "<code>VideoRecording</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Video recorded in an experiment session for Facemap analysis.</p> <p>Attributes:</p> Name Type Description <code>Session</code> <code>foreign key) </code> <p>Primary key for Session table.</p> <code>recording_id</code> <code>int) </code> <p>Recording ID.</p> <code>Device</code> <code>foreign key) </code> <p>Primary key for Device table.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>@schema\nclass VideoRecording(dj.Manual):\n\"\"\"Video recorded in an experiment session for Facemap analysis.\n\n    Attributes:\n        Session (foreign key) : Primary key for Session table.\n        recording_id (int) : Recording ID.\n        Device (foreign key) : Primary key for Device table.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; Session\n    recording_id                : int\n    ---\n    -&gt; Device\n    \"\"\"\n\n    # One VideoRecording can be saved in multiple files\n    class File(dj.Part):\n\"\"\"Relative path of video file with respect to facemap_root_data_dir directory.\n\n        Attributes:\n            master (foreign key) : Primary key for VideoRecording table.\n            file_id (smallint) : File ID.\n            file_path ( varchar(255) ) : Filepath of video, relative to root directory.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        file_id     : smallint\n        ---\n        file_path   : varchar(255)  # filepath of video, relative to root directory\n        \"\"\"\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.VideoRecording.File", "title": "<code>File</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Relative path of video file with respect to facemap_root_data_dir directory.</p> <p>Attributes:</p> Name Type Description <code>master</code> <code>foreign key) </code> <p>Primary key for VideoRecording table.</p> <code>file_id</code> <code>smallint) </code> <p>File ID.</p> <code>file_path</code> <code> varchar(255) ) </code> <p>Filepath of video, relative to root directory.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>class File(dj.Part):\n\"\"\"Relative path of video file with respect to facemap_root_data_dir directory.\n\n    Attributes:\n        master (foreign key) : Primary key for VideoRecording table.\n        file_id (smallint) : File ID.\n        file_path ( varchar(255) ) : Filepath of video, relative to root directory.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    file_id     : smallint\n    ---\n    file_path   : varchar(255)  # filepath of video, relative to root directory\n    \"\"\"\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.RecordingInfo", "title": "<code>RecordingInfo</code>", "text": "<p>         Bases: <code>dj.Imported</code></p> <p>Information extracted from video file.</p> <p>Attributes:</p> Name Type Description <code>VideoRecording</code> <code>foreign key) </code> <p>Primary key for VideoRecording table.</p> <code>px_height</code> <code>int) </code> <p>Height in pixels.</p> <code>px_width</code> <code>int) </code> <p>Width in pixels.</p> <code>nframes</code> <code>int) </code> <p>Number of frames.</p> <code>fps</code> <code>int) </code> <p>Frames per second in Hz.</p> <code>recording_duration</code> <code>float) </code> <p>Video duration in seconds.</p> <code>recording_time</code> <code>datetime, optional) </code> <p>Time at the beginning of the recording.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>@schema\nclass RecordingInfo(dj.Imported):\n\"\"\"Information extracted from video file.\n\n    Attributes:\n        VideoRecording (foreign key) : Primary key for VideoRecording table.\n        px_height (int) : Height in pixels.\n        px_width (int) : Width in pixels.\n        nframes (int) : Number of frames.\n        fps (int) : Frames per second in Hz.\n        recording_duration (float) : Video duration in seconds.\n        recording_time (datetime, optional) : Time at the beginning of the recording.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; VideoRecording\n    ---\n    px_height             : int       # height in pixels\n    px_width              : int       # width in pixels\n    nframes               : int       # number of frames\n    fps                   : int       # frames per second in Hz\n    recording_duration    : float     # video duration in seconds\n    recording_time = NULL : datetime  # time at the beginning of the recording\n    \"\"\"\n\n    @property\n    def key_source(self):\n\"\"\"Limits the population of RecordingInfo to video recordings that have file paths ingested.\"\"\"\n        return VideoRecording &amp; VideoRecording.File\n\n    def make(self, key):\n\"\"\"Populates the RecordingInfo table.\"\"\"\n\n        file_paths = (VideoRecording.File &amp; key).fetch(\"file_path\")\n\n        nframes = 0\n        px_height, px_width, fps = None, None, None\n\n        for file_path in file_paths:\n            file_path = (\n                find_full_path(get_facemap_root_data_dir(), file_path)\n            ).as_posix()\n\n            cap = cv2.VideoCapture(file_path)\n            info = (\n                int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n                int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n                int(cap.get(cv2.CAP_PROP_FPS)),\n            )\n            if px_height is not None:\n                assert (px_height, px_width, fps) == info\n            px_height, px_width, fps = info\n            nframes += int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n            cap.release()\n\n        self.insert1(\n            {\n                **key,\n                \"px_height\": px_height,\n                \"px_width\": px_width,\n                \"nframes\": nframes,\n                \"fps\": fps,  # usually user-defined and wrong\n                \"recording_duration\": nframes / fps,  # see caution above\n            }\n        )\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.RecordingInfo.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Limits the population of RecordingInfo to video recordings that have file paths ingested.</p>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.RecordingInfo.make", "title": "<code>make(key)</code>", "text": "<p>Populates the RecordingInfo table.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def make(self, key):\n\"\"\"Populates the RecordingInfo table.\"\"\"\n\n    file_paths = (VideoRecording.File &amp; key).fetch(\"file_path\")\n\n    nframes = 0\n    px_height, px_width, fps = None, None, None\n\n    for file_path in file_paths:\n        file_path = (\n            find_full_path(get_facemap_root_data_dir(), file_path)\n        ).as_posix()\n\n        cap = cv2.VideoCapture(file_path)\n        info = (\n            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n            int(cap.get(cv2.CAP_PROP_FPS)),\n        )\n        if px_height is not None:\n            assert (px_height, px_width, fps) == info\n        px_height, px_width, fps = info\n        nframes += int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        cap.release()\n\n    self.insert1(\n        {\n            **key,\n            \"px_height\": px_height,\n            \"px_width\": px_width,\n            \"nframes\": nframes,\n            \"fps\": fps,  # usually user-defined and wrong\n            \"recording_duration\": nframes / fps,  # see caution above\n        }\n    )\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacemapTask", "title": "<code>FacemapTask</code>", "text": "<p>         Bases: <code>dj.Manual</code></p> <p>Staging table for pairing of recording and Facemap parameters before processing.</p> <p>Attributes:</p> Name Type Description <code>VideoRecording</code> <code>foreign key) </code> <p>Primary key for VideoRecording table.</p> <code>facemap_task_id</code> <code>smallint) </code> <p>Facemap task ID</p> <code>facemap_output_dir</code> <code> varchar(255), optional) </code> <p>output dir storing the results of Facemap analysis.</p> <code>task_mode</code> <code>enum) </code> <p>Default load. Load or trigger analysis.</p> <code>facemap_params</code> <code>longblob) </code> <p>content of facemap's _proc.npy as dict.</p> <code>do_mot_svd</code> <code>bool) </code> <p>Default 1. Do motion singular value decomposition.</p> <code>do_mov_svd</code> <code>bool) </code> <p>Default 0. Do movie singular value decomposition.</p> <code>task_description</code> <code> varchar(128), optional) </code> <p>Task description.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>@schema\nclass FacemapTask(dj.Manual):\n\"\"\"Staging table for pairing of recording and Facemap parameters before processing.\n\n    Attributes:\n        VideoRecording (foreign key) : Primary key for VideoRecording table.\n        facemap_task_id (smallint) : Facemap task ID\n        facemap_output_dir ( varchar(255), optional) : output dir storing the results\n            of Facemap analysis.\n        task_mode (enum) : Default load. Load or trigger analysis.\n        facemap_params (longblob) : content of facemap's _proc.npy as dict.\n        do_mot_svd (bool) : Default 1. Do motion singular value decomposition.\n        do_mov_svd (bool) : Default 0. Do movie singular value decomposition.\n        task_description ( varchar(128), optional) : Task description.\n    \"\"\"\n\n    definition = \"\"\"\n    # Staging table for pairing of recording and Facemap parameters before processing.\n    -&gt; VideoRecording\n    facemap_task_id             : smallint\n    ---\n    facemap_output_dir=''       : varchar(255)  # output directory - storing the results of Facemap analysis\n    task_mode='load'            : enum('load', 'trigger')\n    facemap_params              : longblob  # content of facemap's _proc.npy as dict\n    do_mot_svd=1                : bool\n    do_mov_svd=0                : bool\n    task_description=''         : varchar(128)\n    \"\"\"\n\n    def infer_output_dir(self, key, relative=True, mkdir=True):\n        video_file = (VideoRecording.File &amp; key).fetch(\"file_path\", limit=1)[0]\n        video_dir = find_full_path(get_facemap_root_data_dir(), video_file).parent\n        root_dir = find_root_directory(get_facemap_root_data_dir(), video_dir)\n\n        paramset_key = (FacemapTask &amp; key).fetch1(\"facemap_task_id\")\n        processed_dir = Path(get_facemap_processed_data_dir())\n        output_dir = (\n            processed_dir / video_dir.relative_to(root_dir) / f\"facemap_{paramset_key}\"\n        )\n\n        if mkdir:\n            output_dir.mkdir(parents=True, exist_ok=True)\n\n        return output_dir.relative_to(processed_dir) if relative else output_dir\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacemapProcessing", "title": "<code>FacemapProcessing</code>", "text": "<p>         Bases: <code>dj.Computed</code></p> <p>Automated table to run Facemap with inputs from FacemapTask.</p> <p>Attributes:</p> Name Type Description <code>FacemapTask</code> <code>foreign key) </code> <p>Primary key for FacemapTask table.</p> <code>processing_time</code> <code>datetime) </code> <p>Time of generation of the facemap results.</p> <code>package_version</code> <code> varchar(16), optional) </code> <p>Facemap package version.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>@schema\nclass FacemapProcessing(dj.Computed):\n\"\"\"Automated table to run Facemap with inputs from FacemapTask.\n\n    Attributes:\n        FacemapTask (foreign key) : Primary key for FacemapTask table.\n        processing_time (datetime) : Time of generation of the facemap results.\n        package_version ( varchar(16), optional) : Facemap package version.\n    \"\"\"\n\n    definition = \"\"\"\n    # Processing Procedure\n    -&gt; FacemapTask\n    ---\n    processing_time     : datetime  # time of generation of the facemap results\n    package_version=''  : varchar(16)\n    \"\"\"\n\n    # Process only the VideoRecordings that have their Info inserted.\n    @property\n    def key_source(self):\n\"\"\"Limits the population of FacemapProcessing to those that have VideoRecording.File defined.\"\"\"\n        return FacemapTask &amp; VideoRecording.File\n\n    def make(self, key):\n\"\"\"Runs Facemap\"\"\"\n\n        task_mode = (FacemapTask &amp; key).fetch1(\"task_mode\")\n\n        output_dir = (FacemapTask &amp; key).fetch1(\"facemap_output_dir\")\n        if not output_dir:\n            output_dir = FacemapTask().infer_output_dir(key, relative=True, mkdir=True)\n            # update processing_output_dir\n            FacemapTask.update1({**key, \"facemap_output_dir\": output_dir.as_posix()})\n\n        if task_mode == \"trigger\":\n            from facemap.process import run as facemap_run\n\n            params = (FacemapTask &amp; key).fetch1(\"facemap_params\")\n\n            video_files = (FacemapTask * VideoRecording.File &amp; key).fetch(\"file_path\")\n            video_files = [\n                [\n                    find_full_path(get_facemap_root_data_dir(), video_file).as_posix()\n                    for video_file in video_files\n                ]\n            ]\n\n            output_dir = find_full_path(get_facemap_root_data_dir(), output_dir)\n            facemap_run(\n                video_files,\n                sbin=params[\"sbin\"],\n                proc=params,\n                savepath=output_dir.as_posix(),\n                motSVD=params[\"motSVD\"],\n                movSVD=params[\"movSVD\"],\n            )\n\n        _, creation_time = get_loader_result(key, FacemapTask)\n        key = {**key, \"processing_time\": creation_time}\n\n        self.insert1(key)\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacemapProcessing.key_source", "title": "<code>key_source</code>  <code>property</code>", "text": "<p>Limits the population of FacemapProcessing to those that have VideoRecording.File defined.</p>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacemapProcessing.make", "title": "<code>make(key)</code>", "text": "<p>Runs Facemap</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def make(self, key):\n\"\"\"Runs Facemap\"\"\"\n\n    task_mode = (FacemapTask &amp; key).fetch1(\"task_mode\")\n\n    output_dir = (FacemapTask &amp; key).fetch1(\"facemap_output_dir\")\n    if not output_dir:\n        output_dir = FacemapTask().infer_output_dir(key, relative=True, mkdir=True)\n        # update processing_output_dir\n        FacemapTask.update1({**key, \"facemap_output_dir\": output_dir.as_posix()})\n\n    if task_mode == \"trigger\":\n        from facemap.process import run as facemap_run\n\n        params = (FacemapTask &amp; key).fetch1(\"facemap_params\")\n\n        video_files = (FacemapTask * VideoRecording.File &amp; key).fetch(\"file_path\")\n        video_files = [\n            [\n                find_full_path(get_facemap_root_data_dir(), video_file).as_posix()\n                for video_file in video_files\n            ]\n        ]\n\n        output_dir = find_full_path(get_facemap_root_data_dir(), output_dir)\n        facemap_run(\n            video_files,\n            sbin=params[\"sbin\"],\n            proc=params,\n            savepath=output_dir.as_posix(),\n            motSVD=params[\"motSVD\"],\n            movSVD=params[\"movSVD\"],\n        )\n\n    _, creation_time = get_loader_result(key, FacemapTask)\n    key = {**key, \"processing_time\": creation_time}\n\n    self.insert1(key)\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacialSignal", "title": "<code>FacialSignal</code>", "text": "<p>         Bases: <code>dj.Imported</code></p> <p>Results of the Facemap analysis.</p> <p>Attributes:</p> Name Type Description <code>FacemapProcessing</code> <code>foreign key) </code> <p>Primary key for FacemapProcessing table.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>@schema\nclass FacialSignal(dj.Imported):\n\"\"\"Results of the Facemap analysis.\n\n    Attributes:\n        FacemapProcessing (foreign key) : Primary key for FacemapProcessing table.\n    \"\"\"\n\n    definition = \"\"\"# Facemap results\n    -&gt; FacemapProcessing\n    \"\"\"\n\n    class Region(dj.Part):\n\"\"\"Region's properties.\n\n        Attributes:\n            master (foreign key) : Primary key of the FacialSignal table.\n            roi_no (int) : Region number.\n            roi_name ( varchar(16), optional ) : User-friendly name of the roi.\n            xrange (longblob) : 1d np.array - x pixel indices.\n            yrange (longblob) : 1d np.array - y pixel indices.\n            xrange_bin (longblob) : 1d np.array - binned x pixel indices.\n            yrange_bin (longblob) : 1d np.array - binned y pixel indices.\n            motion (longblob) : 1d np.array - absolute motion energies (nframes).\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        roi_no        : int         # Region number\n        ---\n        roi_name=''   : varchar(16) # user-friendly name of the roi\n        xrange        : longblob    # 1d np.array - x pixel indices\n        yrange        : longblob    # 1d np.array - y pixel indices\n        xrange_bin    : longblob    # 1d np.array - binned x pixel indices\n        yrange_bin    : longblob    # 1d np.array - binned y pixel indices\n        motion        : longblob    # 1d np.array - absolute motion energies (nframes)\n        \"\"\"\n\n    class MotionSVD(dj.Part):\n\"\"\"Components of the SVD from motion video.\n\n        Attributes:\n            master.Region (foreign key) : Primary key of the FacialSignal.Region table.\n            pc_no (int) : Principle component (PC) number.\n            singular_value (float, optional) : singular value corresponding to the PC.\n            motmask (longblob) : PC (y, x).\n            projection (longblob) : projections onto the principle component (nframes).\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master.Region\n        pc_no               : int         # principle component (PC) number\n        ---\n        singular_value=null : float       # singular value corresponding to the PC\n        motmask             : longblob    # PC (y, x)\n        projection          : longblob    # projections onto the principle component (nframes)\n        \"\"\"\n\n    class MovieSVD(dj.Part):\n\"\"\"Components of the SVD from movie video.\n\n        Attributes:\n            master.Region (foreign key) : Primary key of the FacialSignal.Region table.\n            pc_no (int) : principle component (PC) number.\n            singular_value (float, optional) : Singular value corresponding to the PC.\n            movmask (longblob) : PC (y, x)\n            projection (longblob) : Projections onto the principle component (nframes).\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master.Region\n        pc_no               : int         # principle component (PC) number\n        ---\n        singular_value=null : float       # singular value corresponding to the PC\n        movmask             : longblob    # PC (y, x)\n        projection          : longblob    # projections onto the principle component (nframes)\n        \"\"\"\n\n    class Summary(dj.Part):\n\"\"\"Average frames for movie and motion videos.\n\n        Attributes:\n            master (foreign key) : Primary key of the FacialSignal table.\n            sbin (int) : Spatial bin size.\n            avgframe (longblob) : 2d np.array - average binned frame.\n            avgmotion (longblob) : 2d nd.array - average binned motion frame.\n        \"\"\"\n\n        definition = \"\"\"\n        -&gt; master\n        ---\n        sbin          : int         # spatial bin size\n        avgframe      : longblob    # 2d np.array - average binned frame\n        avgmotion     : longblob    # 2d nd.array - average binned motion frame\n        \"\"\"\n\n    def make(self, key):\n\"\"\"Populates the FacialSignal table by transferring the results from default\n        Facemap outputs to the database.\"\"\"\n\n        dataset, _ = get_loader_result(key, FacemapTask)\n        # Only motion SVD region type is supported.\n        dataset[\"rois\"] = [x for x in dataset[\"rois\"] if x[\"rtype\"] == \"motion SVD\"]\n\n        self.insert1(key)\n\n        self.Region.insert(\n            [\n                dict(\n                    key,\n                    roi_no=i,\n                    xrange=dataset[\"rois\"][i][\"xrange\"],\n                    yrange=dataset[\"rois\"][i][\"yrange\"],\n                    xrange_bin=dataset[\"rois\"][i][\"xrange_bin\"]\n                    if \"xrange_bin\" in dataset[\"rois\"][i]\n                    else None,\n                    yrange_bin=dataset[\"rois\"][i][\"yrange_bin\"]\n                    if \"yrange_bin\" in dataset[\"rois\"][i]\n                    else None,\n                    motion=dataset[\"motion\"][i + 1],\n                )\n                for i in range(len(dataset[\"rois\"]))\n                if dataset[\"rois\"][i][\"rtype\"] == \"motion SVD\"\n            ]\n        )\n\n        # MotionSVD\n        if any(np.any(x) for x in dataset.get(\"motSVD\", [False])):\n            entry = [\n                dict(\n                    key,\n                    roi_no=roi_no,\n                    pc_no=i,\n                    singular_value=dataset[\"motSv\"][i] if \"motSv\" in dataset else None,\n                    motmask=dataset[\"motMask_reshape\"][roi_no + 1][:, :, i],\n                    projection=dataset[\"motSVD\"][roi_no + 1][i],\n                )\n                for roi_no in range(len(dataset[\"rois\"]))\n                for i in range(dataset[\"motSVD\"][roi_no + 1].shape[1])\n            ]\n            self.MotionSVD.insert(entry)\n\n        # MovieSVD\n        if any(np.any(x) for x in dataset.get(\"movSVD\", [False])):\n            entry = [\n                dict(\n                    key,\n                    roi_no=roi_no,\n                    pc_no=i,\n                    singular_value=dataset[\"movSv\"][i] if \"movSv\" in dataset else None,\n                    movmask=dataset[\"movMask_reshape\"][roi_no + 1][:, :, i],\n                    projection=dataset[\"movSVD\"][roi_no + 1][i],\n                )\n                for roi_no in range(len(dataset[\"rois\"]))\n                for i in range(dataset[\"movSVD\"][roi_no + 1].shape[1])\n            ]\n            self.MovieSVD.insert(entry)\n\n        # Summary\n        self.Summary.insert1(\n            dict(\n                key,\n                sbin=dataset[\"sbin\"],\n                avgframe=dataset[\"avgframe\"][0],\n                avgmotion=dataset[\"avgmotion\"][0],\n            )\n        )\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacialSignal.Region", "title": "<code>Region</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Region's properties.</p> <p>Attributes:</p> Name Type Description <code>master</code> <code>foreign key) </code> <p>Primary key of the FacialSignal table.</p> <code>roi_no</code> <code>int) </code> <p>Region number.</p> <code>roi_name</code> <code> varchar(16), optional ) </code> <p>User-friendly name of the roi.</p> <code>xrange</code> <code>longblob) </code> <p>1d np.array - x pixel indices.</p> <code>yrange</code> <code>longblob) </code> <p>1d np.array - y pixel indices.</p> <code>xrange_bin</code> <code>longblob) </code> <p>1d np.array - binned x pixel indices.</p> <code>yrange_bin</code> <code>longblob) </code> <p>1d np.array - binned y pixel indices.</p> <code>motion</code> <code>longblob) </code> <p>1d np.array - absolute motion energies (nframes).</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>class Region(dj.Part):\n\"\"\"Region's properties.\n\n    Attributes:\n        master (foreign key) : Primary key of the FacialSignal table.\n        roi_no (int) : Region number.\n        roi_name ( varchar(16), optional ) : User-friendly name of the roi.\n        xrange (longblob) : 1d np.array - x pixel indices.\n        yrange (longblob) : 1d np.array - y pixel indices.\n        xrange_bin (longblob) : 1d np.array - binned x pixel indices.\n        yrange_bin (longblob) : 1d np.array - binned y pixel indices.\n        motion (longblob) : 1d np.array - absolute motion energies (nframes).\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    roi_no        : int         # Region number\n    ---\n    roi_name=''   : varchar(16) # user-friendly name of the roi\n    xrange        : longblob    # 1d np.array - x pixel indices\n    yrange        : longblob    # 1d np.array - y pixel indices\n    xrange_bin    : longblob    # 1d np.array - binned x pixel indices\n    yrange_bin    : longblob    # 1d np.array - binned y pixel indices\n    motion        : longblob    # 1d np.array - absolute motion energies (nframes)\n    \"\"\"\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacialSignal.MotionSVD", "title": "<code>MotionSVD</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Components of the SVD from motion video.</p> <p>Attributes:</p> Name Type Description <code>master.Region</code> <code>foreign key) </code> <p>Primary key of the FacialSignal.Region table.</p> <code>pc_no</code> <code>int) </code> <p>Principle component (PC) number.</p> <code>singular_value</code> <code>float, optional) </code> <p>singular value corresponding to the PC.</p> <code>motmask</code> <code>longblob) </code> <p>PC (y, x).</p> <code>projection</code> <code>longblob) </code> <p>projections onto the principle component (nframes).</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>class MotionSVD(dj.Part):\n\"\"\"Components of the SVD from motion video.\n\n    Attributes:\n        master.Region (foreign key) : Primary key of the FacialSignal.Region table.\n        pc_no (int) : Principle component (PC) number.\n        singular_value (float, optional) : singular value corresponding to the PC.\n        motmask (longblob) : PC (y, x).\n        projection (longblob) : projections onto the principle component (nframes).\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master.Region\n    pc_no               : int         # principle component (PC) number\n    ---\n    singular_value=null : float       # singular value corresponding to the PC\n    motmask             : longblob    # PC (y, x)\n    projection          : longblob    # projections onto the principle component (nframes)\n    \"\"\"\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacialSignal.MovieSVD", "title": "<code>MovieSVD</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Components of the SVD from movie video.</p> <p>Attributes:</p> Name Type Description <code>master.Region</code> <code>foreign key) </code> <p>Primary key of the FacialSignal.Region table.</p> <code>pc_no</code> <code>int) </code> <p>principle component (PC) number.</p> <code>singular_value</code> <code>float, optional) </code> <p>Singular value corresponding to the PC.</p> <code>movmask</code> <code>longblob) </code> <p>PC (y, x)</p> <code>projection</code> <code>longblob) </code> <p>Projections onto the principle component (nframes).</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>class MovieSVD(dj.Part):\n\"\"\"Components of the SVD from movie video.\n\n    Attributes:\n        master.Region (foreign key) : Primary key of the FacialSignal.Region table.\n        pc_no (int) : principle component (PC) number.\n        singular_value (float, optional) : Singular value corresponding to the PC.\n        movmask (longblob) : PC (y, x)\n        projection (longblob) : Projections onto the principle component (nframes).\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master.Region\n    pc_no               : int         # principle component (PC) number\n    ---\n    singular_value=null : float       # singular value corresponding to the PC\n    movmask             : longblob    # PC (y, x)\n    projection          : longblob    # projections onto the principle component (nframes)\n    \"\"\"\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacialSignal.Summary", "title": "<code>Summary</code>", "text": "<p>         Bases: <code>dj.Part</code></p> <p>Average frames for movie and motion videos.</p> <p>Attributes:</p> Name Type Description <code>master</code> <code>foreign key) </code> <p>Primary key of the FacialSignal table.</p> <code>sbin</code> <code>int) </code> <p>Spatial bin size.</p> <code>avgframe</code> <code>longblob) </code> <p>2d np.array - average binned frame.</p> <code>avgmotion</code> <code>longblob) </code> <p>2d nd.array - average binned motion frame.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>class Summary(dj.Part):\n\"\"\"Average frames for movie and motion videos.\n\n    Attributes:\n        master (foreign key) : Primary key of the FacialSignal table.\n        sbin (int) : Spatial bin size.\n        avgframe (longblob) : 2d np.array - average binned frame.\n        avgmotion (longblob) : 2d nd.array - average binned motion frame.\n    \"\"\"\n\n    definition = \"\"\"\n    -&gt; master\n    ---\n    sbin          : int         # spatial bin size\n    avgframe      : longblob    # 2d np.array - average binned frame\n    avgmotion     : longblob    # 2d nd.array - average binned motion frame\n    \"\"\"\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.FacialSignal.make", "title": "<code>make(key)</code>", "text": "<p>Populates the FacialSignal table by transferring the results from default Facemap outputs to the database.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def make(self, key):\n\"\"\"Populates the FacialSignal table by transferring the results from default\n    Facemap outputs to the database.\"\"\"\n\n    dataset, _ = get_loader_result(key, FacemapTask)\n    # Only motion SVD region type is supported.\n    dataset[\"rois\"] = [x for x in dataset[\"rois\"] if x[\"rtype\"] == \"motion SVD\"]\n\n    self.insert1(key)\n\n    self.Region.insert(\n        [\n            dict(\n                key,\n                roi_no=i,\n                xrange=dataset[\"rois\"][i][\"xrange\"],\n                yrange=dataset[\"rois\"][i][\"yrange\"],\n                xrange_bin=dataset[\"rois\"][i][\"xrange_bin\"]\n                if \"xrange_bin\" in dataset[\"rois\"][i]\n                else None,\n                yrange_bin=dataset[\"rois\"][i][\"yrange_bin\"]\n                if \"yrange_bin\" in dataset[\"rois\"][i]\n                else None,\n                motion=dataset[\"motion\"][i + 1],\n            )\n            for i in range(len(dataset[\"rois\"]))\n            if dataset[\"rois\"][i][\"rtype\"] == \"motion SVD\"\n        ]\n    )\n\n    # MotionSVD\n    if any(np.any(x) for x in dataset.get(\"motSVD\", [False])):\n        entry = [\n            dict(\n                key,\n                roi_no=roi_no,\n                pc_no=i,\n                singular_value=dataset[\"motSv\"][i] if \"motSv\" in dataset else None,\n                motmask=dataset[\"motMask_reshape\"][roi_no + 1][:, :, i],\n                projection=dataset[\"motSVD\"][roi_no + 1][i],\n            )\n            for roi_no in range(len(dataset[\"rois\"]))\n            for i in range(dataset[\"motSVD\"][roi_no + 1].shape[1])\n        ]\n        self.MotionSVD.insert(entry)\n\n    # MovieSVD\n    if any(np.any(x) for x in dataset.get(\"movSVD\", [False])):\n        entry = [\n            dict(\n                key,\n                roi_no=roi_no,\n                pc_no=i,\n                singular_value=dataset[\"movSv\"][i] if \"movSv\" in dataset else None,\n                movmask=dataset[\"movMask_reshape\"][roi_no + 1][:, :, i],\n                projection=dataset[\"movSVD\"][roi_no + 1][i],\n            )\n            for roi_no in range(len(dataset[\"rois\"]))\n            for i in range(dataset[\"movSVD\"][roi_no + 1].shape[1])\n        ]\n        self.MovieSVD.insert(entry)\n\n    # Summary\n    self.Summary.insert1(\n        dict(\n            key,\n            sbin=dataset[\"sbin\"],\n            avgframe=dataset[\"avgframe\"][0],\n            avgmotion=dataset[\"avgmotion\"][0],\n        )\n    )\n</code></pre>"}, {"location": "api/element_facemap/facial_behavior_estimation/#element_facemap.facial_behavior_estimation.get_loader_result", "title": "<code>get_loader_result(key, table)</code>", "text": "<p>Retrieve the facemap analysis results.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>dict</code> <p>A primary key for an entry in the provided table.</p> required <code>table</code> <code>dj.Table</code> <p>DataJoint user table from which loaded results are retrieved (i.e. FacemapTask).</p> required <p>Returns:</p> Name Type Description <code>loaded_dataset</code> <code>np.array</code> <p>The results of the facemap analysis.</p> <code>creation_time</code> <code>datetime</code> <p>Date and time that the results files were created.</p> Source code in <code>element_facemap/facial_behavior_estimation.py</code> <pre><code>def get_loader_result(\n    key: dict, table: dj.user_tables.TableMeta\n) -&gt; Tuple[np.array, datetime]:\n\"\"\"Retrieve the facemap analysis results.\n\n    Args:\n        key (dict): A primary key for an entry in the provided table.\n        table (dj.Table): DataJoint user table from which loaded results are retrieved (i.e. FacemapTask).\n\n    Returns:\n        loaded_dataset (np.array): The results of the facemap analysis.\n        creation_time (datetime): Date and time that the results files were created.\n    \"\"\"\n    output_dir = (table &amp; key).fetch1(\"facemap_output_dir\")\n\n    output_path = find_full_path(get_facemap_root_data_dir(), output_dir)\n    output_file = glob(output_path.as_posix() + \"/*_proc.npy\")[0]\n\n    loaded_dataset = np.load(output_file, allow_pickle=True).item()\n    creation_time = datetime.fromtimestamp(Path(output_file).stat().st_ctime)\n\n    return loaded_dataset, creation_time\n</code></pre>"}, {"location": "api/element_facemap/version/", "title": "version.py", "text": "<p>Package metadata.</p>"}]}